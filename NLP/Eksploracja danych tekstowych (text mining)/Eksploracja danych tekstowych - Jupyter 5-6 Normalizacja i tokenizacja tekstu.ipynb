{"cells":[{"cell_type":"markdown","metadata":{"id":"lghmLARqs37u"},"source":["# NORMALIZACJA, TOKENIZACJA I KODOWANIE TEKSTU"]},{"cell_type":"markdown","metadata":{"id":"81M15Rr7s37w"},"source":["<img src=\"tokenization.jpg\"/>\n","źródłó grafiki: https://www.shutterstock.com/pl/image-photo/tokenization-word-concept-on-building-blocks-2327475429\n","autor: SergioVas\n","\n","źródło zbioru danych: https://www.kaggle.com/datasets/yasserh/twitter-tweets-sentiment-dataset"]},{"cell_type":"markdown","metadata":{"id":"U5ryYxaJs37w"},"source":["### Pobranie bibliotek i datasetu"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mg-Rlejys37x","outputId":"f9fcdab0-0245-4046-fc7e-1c4866d655f5"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>textID</th>\n","      <th>text</th>\n","      <th>selected_text</th>\n","      <th>sentiment</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>cb774db0d1</td>\n","      <td>I`d have responded, if I were going</td>\n","      <td>I`d have responded, if I were going</td>\n","      <td>neutral</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>549e992a42</td>\n","      <td>Sooo SAD I will miss you here in San Diego!!!</td>\n","      <td>Sooo SAD</td>\n","      <td>negative</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>088c60f138</td>\n","      <td>my boss is bullying me...</td>\n","      <td>bullying me</td>\n","      <td>negative</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>9642c003ef</td>\n","      <td>what interview! leave me alone</td>\n","      <td>leave me alone</td>\n","      <td>negative</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>358bd9e861</td>\n","      <td>Sons of ****, why couldn`t they put them on t...</td>\n","      <td>Sons of ****,</td>\n","      <td>negative</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>27476</th>\n","      <td>4eac33d1c0</td>\n","      <td>wish we could come see u on Denver  husband l...</td>\n","      <td>d lost</td>\n","      <td>negative</td>\n","    </tr>\n","    <tr>\n","      <th>27477</th>\n","      <td>4f4c4fc327</td>\n","      <td>I`ve wondered about rake to.  The client has ...</td>\n","      <td>, don`t force</td>\n","      <td>negative</td>\n","    </tr>\n","    <tr>\n","      <th>27478</th>\n","      <td>f67aae2310</td>\n","      <td>Yay good for both of you. Enjoy the break - y...</td>\n","      <td>Yay good for both of you.</td>\n","      <td>positive</td>\n","    </tr>\n","    <tr>\n","      <th>27479</th>\n","      <td>ed167662a5</td>\n","      <td>But it was worth it  ****.</td>\n","      <td>But it was worth it  ****.</td>\n","      <td>positive</td>\n","    </tr>\n","    <tr>\n","      <th>27480</th>\n","      <td>6f7127d9d7</td>\n","      <td>All this flirting going on - The ATG smiles...</td>\n","      <td>All this flirting going on - The ATG smiles. Y...</td>\n","      <td>neutral</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>27480 rows × 4 columns</p>\n","</div>"],"text/plain":["           textID                                               text  \\\n","0      cb774db0d1                I`d have responded, if I were going   \n","1      549e992a42      Sooo SAD I will miss you here in San Diego!!!   \n","2      088c60f138                          my boss is bullying me...   \n","3      9642c003ef                     what interview! leave me alone   \n","4      358bd9e861   Sons of ****, why couldn`t they put them on t...   \n","...           ...                                                ...   \n","27476  4eac33d1c0   wish we could come see u on Denver  husband l...   \n","27477  4f4c4fc327   I`ve wondered about rake to.  The client has ...   \n","27478  f67aae2310   Yay good for both of you. Enjoy the break - y...   \n","27479  ed167662a5                         But it was worth it  ****.   \n","27480  6f7127d9d7     All this flirting going on - The ATG smiles...   \n","\n","                                           selected_text sentiment  \n","0                    I`d have responded, if I were going   neutral  \n","1                                               Sooo SAD  negative  \n","2                                            bullying me  negative  \n","3                                         leave me alone  negative  \n","4                                          Sons of ****,  negative  \n","...                                                  ...       ...  \n","27476                                             d lost  negative  \n","27477                                      , don`t force  negative  \n","27478                          Yay good for both of you.  positive  \n","27479                         But it was worth it  ****.  positive  \n","27480  All this flirting going on - The ATG smiles. Y...   neutral  \n","\n","[27480 rows x 4 columns]"]},"execution_count":19,"metadata":{},"output_type":"execute_result"}],"source":["# import bibliotek\n","import pandas as pd\n","import nltk\n","from nltk.corpus import stopwords\n","import warnings\n","warnings.filterwarnings('ignore')\n","# import zbioru danych z tweetami\n","train = pd.read_csv('Tweets.csv')\n","train.dropna()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jKBHeEPZs37x","outputId":"0abfdf06-cb2e-449e-f017-0cceb0bd2b20"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>textID</th>\n","      <th>text</th>\n","      <th>selected_text</th>\n","      <th>sentiment</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>cb774db0d1</td>\n","      <td>I`d have responded, if I were going</td>\n","      <td>I`d have responded, if I were going</td>\n","      <td>neutral</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>549e992a42</td>\n","      <td>Sooo SAD I will miss you here in San Diego!!!</td>\n","      <td>Sooo SAD</td>\n","      <td>negative</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>088c60f138</td>\n","      <td>my boss is bullying me...</td>\n","      <td>bullying me</td>\n","      <td>negative</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>9642c003ef</td>\n","      <td>what interview! leave me alone</td>\n","      <td>leave me alone</td>\n","      <td>negative</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>358bd9e861</td>\n","      <td>Sons of ****, why couldn`t they put them on t...</td>\n","      <td>Sons of ****,</td>\n","      <td>negative</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>28b57f3990</td>\n","      <td>http://www.dothebouncy.com/smf - some shameles...</td>\n","      <td>http://www.dothebouncy.com/smf - some shameles...</td>\n","      <td>neutral</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>6e0c6d75b1</td>\n","      <td>2am feedings for the baby are fun when he is a...</td>\n","      <td>fun</td>\n","      <td>positive</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>50e14c0bb8</td>\n","      <td>Soooo high</td>\n","      <td>Soooo high</td>\n","      <td>neutral</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>e050245fbd</td>\n","      <td>Both of you</td>\n","      <td>Both of you</td>\n","      <td>neutral</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>fc2cbefa9d</td>\n","      <td>Journey!? Wow... u just became cooler.  hehe....</td>\n","      <td>Wow... u just became cooler.</td>\n","      <td>positive</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["       textID                                               text  \\\n","0  cb774db0d1                I`d have responded, if I were going   \n","1  549e992a42      Sooo SAD I will miss you here in San Diego!!!   \n","2  088c60f138                          my boss is bullying me...   \n","3  9642c003ef                     what interview! leave me alone   \n","4  358bd9e861   Sons of ****, why couldn`t they put them on t...   \n","5  28b57f3990  http://www.dothebouncy.com/smf - some shameles...   \n","6  6e0c6d75b1  2am feedings for the baby are fun when he is a...   \n","7  50e14c0bb8                                         Soooo high   \n","8  e050245fbd                                        Both of you   \n","9  fc2cbefa9d   Journey!? Wow... u just became cooler.  hehe....   \n","\n","                                       selected_text sentiment  \n","0                I`d have responded, if I were going   neutral  \n","1                                           Sooo SAD  negative  \n","2                                        bullying me  negative  \n","3                                     leave me alone  negative  \n","4                                      Sons of ****,  negative  \n","5  http://www.dothebouncy.com/smf - some shameles...   neutral  \n","6                                                fun  positive  \n","7                                         Soooo high   neutral  \n","8                                        Both of you   neutral  \n","9                       Wow... u just became cooler.  positive  "]},"execution_count":20,"metadata":{},"output_type":"execute_result"}],"source":["# wyświetl pierwszych 10 rezultatów\n","train.head(10)"]},{"cell_type":"markdown","metadata":{"id":"Drn0hx5xs37y"},"source":["## Analiza danych tekstowych"]},{"cell_type":"markdown","metadata":{"id":"EezXW9OWs37y"},"source":["### Sprawdź liczbę słów i liter"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QnxE5xh7s37y","outputId":"f289e1ac-2ab1-417a-bb1f-1871d1e7e423"},"outputs":[{"name":"stdout","output_type":"stream","text":["                                                text  word_count\n","0                I`d have responded, if I were going           8\n","1      Sooo SAD I will miss you here in San Diego!!!          11\n","2                          my boss is bullying me...           5\n","3                     what interview! leave me alone           6\n","4   Sons of ****, why couldn`t they put them on t...          15\n","Mean: 13.7794476183545\n"]}],"source":["# oblicz liczbę słów w każdym tekście\n","train['word_count'] = train['text'].apply(lambda x: len(str(x).split(\" \")))\n","print(train[['text','word_count']].head())\n","print(f'Mean: {train.word_count.mean()}')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kUX-pYh6s37z","outputId":"b661d1b6-e7fa-49f1-d903-01a13bb8726f"},"outputs":[{"name":"stdout","output_type":"stream","text":["                                                text  char_count\n","0                I`d have responded, if I were going        36.0\n","1      Sooo SAD I will miss you here in San Diego!!!        46.0\n","2                          my boss is bullying me...        25.0\n","3                     what interview! leave me alone        31.0\n","4   Sons of ****, why couldn`t they put them on t...        75.0\n","Mean: 68.33002183406114\n"]}],"source":["#oblicz liczbę liter w każdym tekście\n","train['char_count'] = train['text'].str.len()\n","print(train[['text','char_count']].head())\n","print(f'Mean: {train.char_count.mean()}')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hNFR9blns370","outputId":"cc1f5101-12c9-40c1-e77f-a113f6397701"},"outputs":[{"name":"stdout","output_type":"stream","text":["                                                text  avg_word\n","0                I`d have responded, if I were going  4.142857\n","1      Sooo SAD I will miss you here in San Diego!!!  3.600000\n","2                          my boss is bullying me...  4.200000\n","3                     what interview! leave me alone  5.200000\n","4   Sons of ****, why couldn`t they put them on t...  4.357143\n","Mean: 4.464102382945475\n"]}],"source":["# średnia ilość liter w słowie\n","def avg_word(sentence):\n","    words = sentence.split()\n","    return (sum(len(word) for word in words)/len(words))\n","\n","train['text'] = train['text'].astype('str')\n","train['avg_word'] = train['text'].apply(lambda x: avg_word(x))\n","print(train[['text','avg_word']].head())\n","print(f'Mean: {train.avg_word.mean()}')"]},{"cell_type":"markdown","metadata":{"id":"MrI2e0q9s370"},"source":["### Stop-słowa"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pjMamiZks371","outputId":"95a860e4-ccef-4b5d-ea98-455e62643e9c"},"outputs":[{"name":"stderr","output_type":"stream","text":["[nltk_data] Downloading package stopwords to /home/michal/nltk_data...\n","[nltk_data]   Package stopwords is already up-to-date!\n"]},{"name":"stdout","output_type":"stream","text":["['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\"]\n","                                                text  stopwords\n","0                I`d have responded, if I were going          3\n","1      Sooo SAD I will miss you here in San Diego!!!          4\n","2                          my boss is bullying me...          2\n","3                     what interview! leave me alone          2\n","4   Sons of ****, why couldn`t they put them on t...          7\n","Mean: 4.358829736909137\n"]}],"source":["nltk.download('stopwords')\n","stop = stopwords.words('english')\n","\n","print(stop[:10])\n","\n","train['stopwords'] = train['text'].apply(lambda x: len([x for x in x.split() if x in stop]))\n","print(train[['text','stopwords']].head())\n","print(f'Mean: {train.stopwords.mean()}')"]},{"cell_type":"markdown","metadata":{"id":"NemF6VDSs371"},"source":["### Hashtagi"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NcYLVXVRs371","outputId":"80244b30-a9b4-4f52-9756-653393e68bb9"},"outputs":[{"name":"stdout","output_type":"stream","text":["                                                  text  hashtags\n","166    #lichfield #tweetup sounds like fun  Hope to...         2\n","167  Big booming thunder storm almost here.  Maybe ...         0\n","168      Few Bevvies 2day in twn..great on a day off!!         0\n","169  first night in myers. just not the same w/out ...         0\n","170                                       good morning         0\n","171                            its the best show EVER!         0\n","172  URL in previous post (to timer job) should be ...         0\n","173  i think iv hurt my tooth  and eilish and cassi...         0\n","174   I want to know when the auditions are Mander!...         0\n","175   or even NOOOOO NOT THE SECRET NAMEREBECCA PLEASE         0\n","176   I miss my neice  can`t wait to see her bad n ...         0\n","177                    i need to get my computer fixed         0\n","178  really hopes her car`s illness is not terminal...         0\n","179  All the cool people I want to find for followi...         1\n","180   no sir...i woulda put honey...but i don`t hav...         0\n","181  who watched X-men origins: wolverine? i totall...         0\n","182   I VOTED!!! do u have a personal myspace? i ke...         0\n","183         I`m sad that I missed you guys last night!         0\n","184  Finally got a call for marriage counseling 3 d...         0\n","185                                            ok then         0\n","Mean: 0.021978821731378044\n"]}],"source":["train['hashtags'] = train['text'].apply(lambda x: len([x for x in x.split() if x.startswith('#')]))\n","print(train[['text','hashtags']].iloc[166:].head(20))\n","print(f'Mean: {train.hashtags.mean()}')"]},{"cell_type":"markdown","metadata":{"id":"UA3iYofps372"},"source":["### Dane numeryczne"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4sBaIq8Ks373","outputId":"5c760cd6-09b4-4f87-d428-2e2c5a05fac9"},"outputs":[{"name":"stdout","output_type":"stream","text":["                                                  text  numerics\n","183         I`m sad that I missed you guys last night!         0\n","184  Finally got a call for marriage counseling 3 d...         1\n","185                                            ok then         0\n","186                                     _420 why baby?         0\n","187  today was the last day of high school for me a...         0\n","188  We`re having an impromptu pool party... Except...         0\n","189   lost my tooth 2day whilst i was eating gum...oww         0\n","190                                   happy 1 year! <3         1\n","191  Oh, I HELLA forgot to say my official good mor...         0\n","192   *phew*  Will make a note in case anyone else ...         0\n","193    WHAT ABOUT ME ??  I VOTE EVERY DAY FOR YOU !...         0\n","194  I`m starving!! This diet is killing me but I c...         0\n","195                                      i talk to you         0\n","196  im soo bored...im deffo missing my music channels         0\n","197           nite nite bday girl  have fun at concert         0\n","198  Had nicotine replacement patch on for 4 hours....         2\n","199  _Sanderson What`s with Twatter lately?  Either...         0\n","200  should be sleeping.  lost my voice a couple da...         0\n","201  http://twitpic.com/66xlm -  hate when my PARKE...         0\n","202             I`ve heard this fall. I`m waiting too!         0\n","Mean: 0.08558640515265092\n"]}],"source":["train['numerics'] = train['text'].apply(lambda x: len([x for x in x.split() if x.isdigit()]))\n","print(train[['text','numerics']].iloc[183:].head(20))\n","print(f'Mean: {train.numerics.mean()}')"]},{"cell_type":"markdown","metadata":{"id":"vprZpeGzs373"},"source":["### Wyrazy zaczynające się wielka literą"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sR5wnCdrs373","outputId":"b3f455df-790e-4a79-e7fa-439b64b0441d"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>text</th>\n","      <th>upper</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>I`d have responded, if I were going</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Sooo SAD I will miss you here in San Diego!!!</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>my boss is bullying me...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>what interview! leave me alone</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Sons of ****, why couldn`t they put them on t...</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                                text  upper\n","0                I`d have responded, if I were going      1\n","1      Sooo SAD I will miss you here in San Diego!!!      2\n","2                          my boss is bullying me...      0\n","3                     what interview! leave me alone      0\n","4   Sons of ****, why couldn`t they put them on t...      0"]},"execution_count":27,"metadata":{},"output_type":"execute_result"}],"source":["train['upper'] = train['text'].apply(lambda x: len([x for x in x.split() if x.isupper()]))\n","train[['text','upper']].head()"]},{"cell_type":"markdown","metadata":{"id":"6XTRiFxQs373"},"source":["Możemy przeanalizować także części mowy, części zdania, nazwane encje oraz wzajemne zależnosci między słowami w zdaniu."]},{"cell_type":"code","source":["import nltk\n","import textblob\n","nltk.download('averaged_perceptron_tagger')\n","nltk.download('averaged_perceptron_tagger')\n","pos_family = {\n","    'noun' : ['NN','NNS','NNP','NNPS'],\n","    'pron' : ['PRP','PRP$','WP','WP$'],\n","    'verb' : ['VB','VBD','VBG','VBN','VBP','VBZ'],\n","    'adj' :  ['JJ','JJR','JJS'],\n","    'adv' : ['RB','RBR','RBS','WRB']\n","}\n","\n","# function to check and get the part of speech tag count of a words in a given sentence\n","def check_pos_tag(x, flag):\n","    cnt = 0\n","    try:\n","        wiki = textblob.TextBlob(x)\n","        for tup in wiki.tags:\n","            ppo = list(tup)[1]\n","            if ppo in pos_family[flag]:\n","                cnt += 1\n","    except:\n","        pass\n","    return cnt\n","\n","train['noun_count'] = train['text'].apply(lambda x: check_pos_tag(x, 'noun'))\n","train['verb_count'] = train['text'].apply(lambda x: check_pos_tag(x, 'verb'))\n","train['adj_count'] = train['text'].apply(lambda x: check_pos_tag(x, 'adj'))\n","train['adv_count'] = train['text'].apply(lambda x: check_pos_tag(x, 'adv'))\n","train['pron_count'] = train['text'].apply(lambda x: check_pos_tag(x, 'pron'))"],"metadata":{"id":"HfPPgg2VtFKj"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"YRuQb1pVs373"},"source":["## Normalizacja danych tekstowych"]},{"cell_type":"markdown","metadata":{"id":"NsQ8ISjfs374"},"source":["### Ujednolicenie pisowni - zmiana na małe litery"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"eiWCSKxRs374","outputId":"1d6569b1-c5e8-4fdc-fc43-cf17f38c1843"},"outputs":[{"data":{"text/plain":["0                  i`d have responded, if i were going\n","1        sooo sad i will miss you here in san diego!!!\n","2                            my boss is bullying me...\n","3                       what interview! leave me alone\n","4    sons of ****, why couldn`t they put them on th...\n","Name: text, dtype: object"]},"execution_count":28,"metadata":{},"output_type":"execute_result"}],"source":["train['text'] = train['text'].apply(lambda x: \" \".join(x.lower() for x in x.split()))\n","train['text'].head()"]},{"cell_type":"markdown","metadata":{"id":"WPCW2fEjs374"},"source":["### Usunięcie znaków specjalnych oraz liczb"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2FTD7Ipys374","outputId":"9f217754-a4d2-49ce-bec1-beed07a64a88"},"outputs":[{"data":{"text/plain":["0                    id have responded if i were going\n","1           sooo sad i will miss you here in san diego\n","2                               my boss is bullying me\n","3                        what interview leave me alone\n","4    sons of  why couldnt they put them on the rele...\n","Name: text, dtype: object"]},"execution_count":11,"metadata":{},"output_type":"execute_result"}],"source":["train['text'] = train['text'].str.replace('[^\\w\\s]','')\n","train['text'].head()"]},{"cell_type":"markdown","metadata":{"id":"XxD2Eu6xs375"},"source":["## Usunięcie stop-słów"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CnZnd-_8s375","outputId":"7b4087ba-4138-46d1-b1bb-27df766892a8"},"outputs":[{"data":{"text/plain":["0                          id responded going\n","1                     sooo sad miss san diego\n","2                               boss bullying\n","3                       interview leave alone\n","4    sons couldnt put releases already bought\n","Name: text, dtype: object"]},"execution_count":12,"metadata":{},"output_type":"execute_result"}],"source":["stop = stopwords.words('english')\n","train['text'] = train['text'].apply(lambda x: \" \".join(x for x in x.split() if x not in stop))\n","train['text'].head()"]},{"cell_type":"markdown","metadata":{"id":"_aJxiUems375"},"source":["### Usunięcie często występujacych słów"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DdtR1agcs375","outputId":"0273b1e9-7393-43d2-c30f-9578fe29e326"},"outputs":[{"name":"stdout","output_type":"stream","text":["im       3024\n","day      2044\n","good     1549\n","get      1426\n","like     1346\n","go       1266\n","dont     1200\n","love     1122\n","work     1112\n","going    1096\n","dtype: int64\n"]}],"source":["freq = pd.Series(' '.join(train['text']).split()).value_counts()\n","freq = freq[freq > 500]\n","print(freq[:10])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LFqMh77Ts375","outputId":"8ee64686-86f1-4564-f7ca-c58eb76d422d"},"outputs":[{"data":{"text/plain":["0                                id responded\n","1                          sooo sad san diego\n","2                               boss bullying\n","3                       interview leave alone\n","4    sons couldnt put releases already bought\n","Name: text, dtype: object"]},"execution_count":14,"metadata":{},"output_type":"execute_result"}],"source":["freq = list(freq.index)\n","train['text'] = train['text'].apply(lambda x: \" \".join(x for x in x.split() if x not in freq))\n","train['text'].head()"]},{"cell_type":"markdown","metadata":{"id":"3akBqjHPs376"},"source":["### Usunięcie rzadko występujacych słów"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nddDeYyOs376","outputId":"ffe8887c-95b0-461c-9d48-b10e81f2b04b"},"outputs":[{"name":"stdout","output_type":"stream","text":["nano           4\n","newest         4\n","blocking       4\n","nonetheless    4\n","argument       4\n","srry           4\n","alike          4\n","invitation     4\n","930            4\n","jays           4\n","dtype: int64\n"]}],"source":["freq = pd.Series(' '.join(train['text']).split()).value_counts()\n","freq = freq[freq < 5]\n","print(freq[:10])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"85ctzq0bs376","outputId":"5935e44c-b03d-438b-865c-ccdac1a0bf97"},"outputs":[{"data":{"text/plain":["0                                 id\n","1                 sooo sad san diego\n","2                               boss\n","3              interview leave alone\n","4    sons couldnt put already bought\n","Name: text, dtype: object"]},"execution_count":16,"metadata":{},"output_type":"execute_result"}],"source":["freq = list(freq.index)\n","train['text'] = train['text'].apply(lambda x: \" \".join(x for x in x.split() if x not in freq))\n","train['text'].head()"]},{"cell_type":"markdown","metadata":{"id":"ROH7Igyds376"},"source":["### Stemming - usunięcie końcówek dla różnych form"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uDr6s43is376","outputId":"d81873a8-ad51-46bb-dff8-5a8c17c16852"},"outputs":[{"data":{"text/plain":["0                                id\n","1                sooo sad san diego\n","2                              boss\n","3               interview leav alon\n","4    son couldnt put alreadi bought\n","Name: text, dtype: object"]},"execution_count":19,"metadata":{},"output_type":"execute_result"}],"source":["from nltk.stem import PorterStemmer\n","st = PorterStemmer()\n","train['text'][:5].apply(lambda x: \" \".join([st.stem(word) for word in x.split()]))"]},{"cell_type":"markdown","metadata":{"id":"kJHFXl3Ts376"},"source":["### Lematyzacja - zamiana słów ich podstawową formą"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qa8vJcgxs376","outputId":"888e01ac-91d6-42f1-bdf5-0d4fe28736f3"},"outputs":[{"name":"stderr","output_type":"stream","text":["[nltk_data] Downloading package omw-1.4 to /home/michal/nltk_data...\n","[nltk_data]   Package omw-1.4 is already up-to-date!\n","[nltk_data] Downloading package wordnet to /home/michal/nltk_data...\n","[nltk_data]   Package wordnet is already up-to-date!\n"]},{"data":{"text/plain":["0                                id\n","1                sooo sad san diego\n","2                               bos\n","3             interview leave alone\n","4    son couldnt put already bought\n","Name: text, dtype: object"]},"execution_count":20,"metadata":{},"output_type":"execute_result"}],"source":["from textblob import Word\n","nltk.download('omw-1.4')\n","nltk.download('wordnet')\n","train['text'] = train['text'].apply(lambda x: \" \".join([Word(word).lemmatize() for word in x.split()]))\n","train['text'].head()"]},{"cell_type":"markdown","metadata":{"id":"Qk8WRDots376"},"source":["## Tokenizacja tekstu (kodowanie do postaci numerycznej)"]},{"cell_type":"markdown","metadata":{"id":"eFR0ete-s377"},"source":["### N-gramy"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_AD-6Z7es377","outputId":"f4ee9dc8-8e90-4adf-be71-37d6e1afd8e2"},"outputs":[{"data":{"text/plain":["[WordList(['son', 'couldnt']),\n"," WordList(['couldnt', 'put']),\n"," WordList(['put', 'already']),\n"," WordList(['already', 'bought'])]"]},"execution_count":21,"metadata":{},"output_type":"execute_result"}],"source":["TextBlob(train['text'][4]).ngrams(2)"]},{"cell_type":"markdown","metadata":{"id":"uBOOgL2us377"},"source":["### TF-IDF"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"eJDAjFHNs377","outputId":"1f370633-02d0-4347-ddf2-7f9ab39c54d1"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>words</th>\n","      <th>tf</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>sooo</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>sad</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>i</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>will</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>miss</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>you</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>here</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>in</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>san</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>diego!!!</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["      words  tf\n","0      sooo   1\n","1       sad   1\n","2         i   1\n","3      will   1\n","4      miss   1\n","5       you   1\n","6      here   1\n","7        in   1\n","8       san   1\n","9  diego!!!   1"]},"execution_count":34,"metadata":{},"output_type":"execute_result"}],"source":["#TF - ile razy słowo występuje w danym tekście\n","#IDF - logarytm dziesiętny z liczby wszystkich tekstów w zbiorze podzielonej przez liczbę tekstów w których wystepuje dane słowo\n","tf1 = (train['text'][1:2]).apply(lambda x: pd.value_counts(x.split(\" \"))).sum(axis = 0).reset_index()\n","tf1.columns = ['words','tf']\n","tf1"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"R_197S9Ts377","outputId":"1437cc16-2743-4973-f91c-59715a3e28bc"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>words</th>\n","      <th>tf</th>\n","      <th>idf</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>sooo</td>\n","      <td>1</td>\n","      <td>4.791905</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>sad</td>\n","      <td>1</td>\n","      <td>3.935252</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>san</td>\n","      <td>1</td>\n","      <td>5.972755</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>diego</td>\n","      <td>1</td>\n","      <td>7.823355</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   words  tf       idf\n","0   sooo   1  4.791905\n","1    sad   1  3.935252\n","2    san   1  5.972755\n","3  diego   1  7.823355"]},"execution_count":23,"metadata":{},"output_type":"execute_result"}],"source":["import numpy as np\n","for i,word in enumerate(tf1['words']):\n","  tf1.loc[i, 'idf'] = np.log(train.shape[0]/(len(train[train['text'].str.contains(word)])))\n","tf1"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BKwgjK6ns378","outputId":"ba974a3e-8c74-49e8-9d42-615242755206"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>words</th>\n","      <th>tf</th>\n","      <th>idf</th>\n","      <th>tfidf</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>sooo</td>\n","      <td>1</td>\n","      <td>4.791905</td>\n","      <td>4.791905</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>sad</td>\n","      <td>1</td>\n","      <td>3.935252</td>\n","      <td>3.935252</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>san</td>\n","      <td>1</td>\n","      <td>5.972755</td>\n","      <td>5.972755</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>diego</td>\n","      <td>1</td>\n","      <td>7.823355</td>\n","      <td>7.823355</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   words  tf       idf     tfidf\n","0   sooo   1  4.791905  4.791905\n","1    sad   1  3.935252  3.935252\n","2    san   1  5.972755  5.972755\n","3  diego   1  7.823355  7.823355"]},"execution_count":24,"metadata":{},"output_type":"execute_result"}],"source":["tf1['tfidf'] = tf1['tf'] * tf1['idf']\n","tf1"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NAnCBFWas378","outputId":"522a320b-0735-405e-9166-35e53ec7b510"},"outputs":[{"data":{"text/plain":["<27481x1000 sparse matrix of type '<class 'numpy.float64'>'\n","\twith 81354 stored elements in Compressed Sparse Row format>"]},"execution_count":25,"metadata":{},"output_type":"execute_result"}],"source":["from sklearn.feature_extraction.text import TfidfVectorizer\n","tfidf = TfidfVectorizer(max_features=1000, lowercase=True, analyzer='word',\n"," stop_words= 'english',ngram_range=(1,1))\n","train_vect = tfidf.fit_transform(train['text'])\n","\n","train_vect"]},{"cell_type":"markdown","metadata":{"id":"ERNmeoTSs378"},"source":["### Worek słów"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2MYnjsx7s378","outputId":"fc443345-d408-4577-9e4f-f3f3bb9a3225"},"outputs":[{"data":{"text/plain":["<27481x1000 sparse matrix of type '<class 'numpy.int64'>'\n","\twith 91577 stored elements in Compressed Sparse Row format>"]},"execution_count":26,"metadata":{},"output_type":"execute_result"}],"source":["#utwórz słownik\n","from sklearn.feature_extraction.text import CountVectorizer\n","bow = CountVectorizer(max_features=1000, lowercase=True, ngram_range=(1,2),analyzer = \"word\")\n","train_bow = bow.fit_transform(train['text'])\n","train_bow"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9J8kbXvJs378","outputId":"c6d4b1e5-5f42-41ca-9609-ca203f85e063"},"outputs":[{"data":{"text/plain":["dict_keys(['id', 'sooo', 'sad', 'interview', 'leave', 'alone', 'son', 'couldnt', 'put', 'already', 'bought', 'best', 'baby', 'smile', 'soooo', 'high', 'wow', 'hehe', 'chance', 'never', 'gonna', 'cake', 'stuff', 'song', 'story', 'taylor', 'running', 'low', 'music', 'tonight', 'lost', 'voice', 'test', 'trying', 'sigh', 'ive', 'sick', 'past', 'day', 'hair', 'look', 'didnt', 'every', 'he', 'sorry', 'find', 'soon', 'playing', 'online', 'interesting', 'update', 'job', 'wait', 'cleaning', 'house', 'family', 'later', 'gotta', 'computer', 'thought', 'supposed', 'end', 'mean', 'bout', 'called', 'friday', 'free', 'app', 'ipod', 'way', 'internet', 'came', 'omg', 'havent', 'minute', 'went', 'sleep', 'power', 'cut', 'working', 'seen', 'make', 'hahaha', 'say', '10', 'funny', 'cute', 'kid', 'ahhh', 'slept', 'game', 'try', 'watch', 'tomorrow', 'though', 'play', 'tear', 'nyc', 'living', 'year', 'case', 'wonder', 'busy', 'coming', 'ton', 'stay', 'school', 'little', 'wine', 'ok', 'care', 'car', 'big', 'hoping', 'theyre', 'write', 'finger', 'waiting', 'fan', 'thing', 'show', 'bad', 'boy', 'available', 'dear', 'help', 'girl', 'shall', 'old', 'dunno', 'wanna', 'drunk', 'facebook', 'also', 'shopping', 'money', 'round', 'looking', 'week', 'mine', 'check', 'hate', 'bored', 'guess', 'rather', 'early', 'ran', 'late', 'bag', 'knee', 'hurt', 'aw', 'friend', 'yes', 'give', 'better', 'mum', 'let', 'nice', 'bottle', 'favorite', 'red', 'iphone', 'jealous', 'awesome', 'worked', 'yay', 'boo', 'right', 'sound', 'anyone', 'extra', 'ticket', 'buy', 'drink', 'take', 'pic', 'fb', 'blog', 'etc', 'ride', 'catch', 'summer', 'til', 'open', 'yea', 'yesterday', 'hospital', 'said', 'hi', 'probably', 'head', 'tired', 'hey', 'change', 'account', 'even', 'tell', 'thank', 'lucky', 'fell', 'asleep', 'flu', 'reply', 'problem', 'video', 'guy', 'star', 'war', 'everyone', 'enjoy', 'holiday', 'uk', 'star war', 'mile', 'least', 'annoying', 'keep', 'sleeping', 'left', 'isnt', 'quite', 'ready', 'post', 'cool', 'eating', 'ice', 'cream', 'getting', 'graduation', 'ice cream', 'getting ready', 'gone', 'shes', 'cause', 'unfortunately', 'read', 'bed', 'saw', 'none', 'beach', 'pretty', 'cheer', 'huh', 'next', 'starting', 'hand', 'ouch', 'wanted', 'real', 'wear', 'black', 'safe', 'trip', 'dead', 'add', 'email', 'comment', 'aww', 'daddy', 'work', 'almost', 'many', 'done', 'hang', 'trek', 'star trek', 'making', 'food', 'worry', 'itunes', 'whats', 'weather', 'sun', 'must', 'come', 'heading', 'forward', 'math', 'english', 'french', 'exam', 'hour', 'looking forward', 'next week', 'poor', 'outside', 'garden', 'forget', 'prob', 'hun', 'dad', 'watching', 'absolutely', 'matter', 'totally', 'cd', 'nothing', 'bank', 'monday', 'bank holiday', 'ask', 'something', 'lmao', 'mr', 'tweeting', 'sunday', 'may', 'mom', 'decided', 'whole', 'looked', 'age', 'people', 'word', 'congrats', 'missed', 'movie', 'group', 'call', 'longer', 'fly', 'drive', 'actually', 'google', 'suck', 'tho', 'watched', 'win', 'sore', 'throat', 'beat', 'suppose', 'lunch', 'cousin', 'whatever', 'tweet', 'three', 'mention', 'glass', 'fine', 'walk', '20', 'one', 'two', 'yeah', 'forgot', 'machine', 'sending', 'ah', 'feeling', 'god', 'bless', 'nope', 'parent', 'boring', 'saturday', 'else', 'maybe', '2day', 'first', 'excited', 'ever', 'text', 'please', 'fixed', 'following', 'wolverine', 'loved', 'myspace', 'talking', 'thru', 'life', 'finally', 'ended', 'stupid', 'high school', 'pool', 'party', 'except', 'hear', 'note', 'run', 'vote', 'eat', 'talk', 'soo', 'missing', 'nite', 'bday', 'concert', 'far', 'bit', 'lately', 'either', 'turn', 'couple', 'ago', 'get', 'hit', 'heard', 'fall', 'disappointed', 'headache', 'coffee', 'breakfast', 'thinking', 'dude', 'plan', 'huge', 'store', 'youre', 'hahah', 'traffic', 'lil', 'homework', 'youve', 'walking', 'class', 'failed', 'pas', 'sold', 'worse', 'jonas', 'brother', 'live', 'hard', 'world', 'lot', 'sleepy', 'episode', 'short', 'yum', 'review', 'enough', 'followed', 'hopefully', 'meant', 'meeting', 'always', 'thx', 'luv', 'okay', 'fact', 'apple', 'screen', 'could', 'long', 'bar', 'rest', 'seriously', 'pain', 'bring', 'follower', 'died', 'laptop', 'set', '100', 'window', 'pick', 'study', 'shower', 'bug', 'fix', 'die', 'cry', 'small', 'writing', 'card', 'amazing', 'news', 'finished', 'band', 'wonderful', 'another', 'seeing', 'listening', 'someone', 'hell', 'shirt', 'dinner', 'mind', 'anyway', 'birthday', 'ate', 'woke', 'side', 'wish', 'person', 'laugh', 'glad', 'stuck', 'inside', 'felt', 'sorry hear', 'meet', 'pay', 'bc', 'park', 'yep', 'full', 'true', 'remember', 'date', 'gorgeous', 'goin', 'till', 'top', 'em', 'made', 'cat', 'break', 'fam', 'egg', 'learn', 'worth', 'shot', 'seems', 'cannot', 'happened', 'shame', 'office', 'tv', 'found', 'definitely', 'weekend', 'ur', 'flight', 'cancelled', 'ohh', 'taking', 'follow', 'others', 'feelin', 'bill', 'broke', 'sure', 'planning', 'time', 'gig', 'sit', 'mate', 'without', 'relaxing', 'awake', 'wake', 'mommy', 'dog', 'officially', 'doesnt', 'realized', 'exciting', 'start', 'tonite', 'agree', 'everything', 'degree', 'mood', 'dang', 'moving', 'crazy', 'fever', 'spending', 'book', 'using', 'fair', 'ya', 'hungry', 'send', 'message', 'telling', 'beer', 'btw', 'phone', 'told', 'might', 'sadly', 'driving', 'version', 'youll', '25', '30', 'woo', 'face', 'believe', 'warm', 'welcome', 'air', 'use', 'nail', 'camera', 'door', 'caught', 'since', 'need', 'away', 'around', 'idea', 'business', 'film', 'afternoon', 'fantastic', 'met', 'evening', 'save', 'packing', 'tea', 'history', 'kill', 'key', 'stopped', 'name', 'took', 'john', 'picture', 'anymore', 'love', 'photo', 'prom', 'foot', 'wishing', 'boyfriend', 'forever', 'giving', 'easy', 'beautiful', 'usually', '15', 'min', 'company', 'together', 'lovely', 'kind', 'weird', 'singing', 'daughter', 'bird', 'man', 'yet', 'radio', 'street', 'wont', 'moon', 'kiss', 'anything', 'scared', 'leg', 'instead', 'shop', 'random', 'proud', 'spend', 'congratulation', 'finish', 'month', 'june', 'sometimes', 'tip', 'quick', 'wasnt', 'rock', 'support', 'there', 'moment', 'fail', 'enjoyed', 'feel', 'mama', 'lonely', 'alot', 'hot', 'clean', 'wearing', 'clothes', 'half', 'men', 'cuz', 'place', 'cost', 'part', 'answer', 'sister', 'london', 'figure', 'aint', 'quiet', 'afraid', 'make sad', 'sweet', 'dream', 'chat', 'happen', 'idk', 'sunshine', 'issue', 'close', 'join', 'yup', 'super', 'eye', 'site', 'train', 'stop', 'sign', 'although', 'bet', 'arent', 'mother', 'body', 'worst', 'posted', 'move', 'child', 'ear', 'kinda', 'hello', 'go', 'followfriday', 'list', 'ugh', 'tried', 'doctor', 'everybody', 'yummy', 'started', 'different', 'vega', 'cold', 'bgt', 'iï½m', 'final', 'rain', '1st', 'rip', 'wheres', 'present', 'gift', 'think', 'wondering', 'college', 'young', 'room', 'mad', 'wife', 'ring', 'point', 'question', 'gave', 'link', 'sitting', 'sunny', 'luck', 'vacation', 'heart', 'leaving', 'sat', 'anytime', 'gym', 'waking', 'knew', 'block', 'tour', '12', 'twilight', 'yall', 'blood', 'shoe', 'everyday', 'race', 'especially', 'hubby', 'web', 'completely', 'dm', 'awww', 'broken', 'light', 'spent', 'topic', 'count', 'lesson', 'youtube', 'saying', 'load', 'stomach', 'awful', 'paper', 'hmm', 'thanx', 'church', 'chicken', 'goodnight', 'starbucks', 'perfect', 'b4', 'alright', 'make sure', 'copy', 'public', 'contact', 'deal', 'hannah', 'mac', 'airport', 'jus', 'blue', 'staying', 'moved', 'arm', 'dance', 'drinking', 'reason', 'enjoying', 'favourite', 'yr', 'ha', 'wedding', 'american', 'lazy', 'thursday', 'killed', 'near', '4th', 'war may', 'may 4th', 'guitar', 'want', 'page', 'calling', 'fast', 'understand', 'state', 'ball', 'heat', 'horrible', 'coz', 'checked', 'visit', 'box', 'studying', 'wrong', 'xd', 'gutted', 'babe', 'reading', 'track', 'bloody', 'bike', 'able', 'ff', 'da', 'woman', 'momma', 'ppl', 'hr', 'sent', 'snl', 'joke', 'become', 'city', 'number', 'session', 'slow', 'plus', 'freakin', 'itll', 'bus', 'white', 'chocolate', 'hug', 'best friend', 'profile', 'outta', 'justin', 'goodbye', 'sexy', 'course', 'pizza', 'eh', 'along', 'tuesday', 'bye', 'better soon', 'paid', 'cup', 'season', 'loving', 'behind', 'wtf', 'share', 'lame', 'hanging', 'swine', 'swine flu', 'tom', 'hows', 'somewhere', 'wont let', 'club', 'line', 'due', 'revision', 'memory', 'middle', 'lady', 'bbq', 'needed', 'water', 'sale', 'july', 'played', 'return', 'talent', 'hold', 'changed', 'night', 'dvd', 'ooh', 'dress', 'fav', 'quote', 'raining', 'second', 'upset', 'service', 'cover', '2nd', 'liked', 'la', 'exactly', 'cheese', 'dark', 'seem', 'town', 'ima', 'milk', 'david', 'dancing', 'co', 'download', '11', 'touch', 'scary', 'ahh', 'front', 'listen', 'apparently', 'green', 'album', 'le', 'yo', 'currently', 'mmm', 'gettin', 'anyways', 'stand', 'pc', 'bummed', 'art', 'team', 'order', 'website', 'earlier', 'delicious', 'youre welcome', 'flower', 'used', 'bro', 'imagine', 'tummy', 'travel', 'road', 'hilarious', 'special', 'puppy', 'appreciate', 'code', 'taken', 'single', 'xoxo', 'via', 'mobile', 'project', 'chillin', 'rainy', 'sing', 'brought', 'apartment', 'five', 'closed', 'nobody', 'wouldnt', 'wednesday', 'brain', 'bummer', 'thank god', 'happens', 'indeed', 'nap', 'event'])"]},"execution_count":27,"metadata":{},"output_type":"execute_result"}],"source":["bow.vocabulary_.keys()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0IfB8WBTs379","outputId":"77b3ee91-1e28-4207-ee1c-3777338e861b"},"outputs":[{"data":{"text/plain":["1000"]},"execution_count":28,"metadata":{},"output_type":"execute_result"}],"source":["len(bow.vocabulary_.keys())"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PGBl1twJs379","outputId":"a1fc0863-212d-4de1-9471-b6e03ed17926"},"outputs":[{"name":"stdout","output_type":"stream","text":["sooo sad san diego\n","  (0, 708)\t1\n","  (0, 778)\t1\n"]}],"source":["from scipy import sparse\n","text = train['text'][1]\n","print(text)\n","decoded = sparse.csr_matrix(bow.transform([text]))\n","print(decoded)"]},{"cell_type":"markdown","metadata":{"id":"mkqcHAgEs379"},"source":["### Word embedding"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cC8f22Izs379","outputId":"793fec7a-1ef4-4206-c59e-115973b41eb9"},"outputs":[{"data":{"text/plain":["(400000, 100)"]},"execution_count":46,"metadata":{},"output_type":"execute_result"}],"source":["# przed uruchomieniem pobierz:\n","# http://nlp.stanford.edu/data/glove.6B.zip\n","\n","from gensim.scripts.glove2word2vec import glove2word2vec\n","glove_input_file = 'glove.6B.100d.txt'\n","word2vec_output_file = 'glove.6B.100d.txt.word2vec'\n","glove2word2vec(glove_input_file, word2vec_output_file)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sCIVIlyYs37-"},"outputs":[],"source":["from gensim.models import KeyedVectors # load the Stanford GloVe model\n","filename = 'glove.6B.100d.txt.word2vec'\n","model = KeyedVectors.load_word2vec_format(filename, binary=False)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fv6KoiYhs37-","outputId":"eb263776-419d-489b-a767-6b03c8a8147e"},"outputs":[{"data":{"text/plain":["array([-0.078894,  0.4616  ,  0.57779 , -0.71637 , -0.13121 ,  0.4186  ,\n","       -0.29156 ,  0.52006 ,  0.089986, -0.35062 ,  0.51755 ,  0.51998 ,\n","        0.15218 ,  0.41485 , -0.12377 , -0.37222 ,  0.0273  ,  0.75673 ,\n","       -0.8739  ,  0.58935 ,  0.46662 ,  0.62918 ,  0.092603, -0.012868,\n","       -0.015169,  0.25567 , -0.43025 , -0.77668 ,  0.71449 , -0.3834  ,\n","       -0.69638 ,  0.23522 ,  0.11396 ,  0.02778 ,  0.071357,  0.87409 ,\n","       -0.1281  ,  0.063576,  0.067867, -0.50181 , -0.28523 , -0.072536,\n","       -0.50738 , -0.6914  , -0.53579 , -0.11361 , -0.38234 , -0.12414 ,\n","        0.011214, -1.1622  ,  0.037057, -0.18495 ,  0.01416 ,  0.87193 ,\n","       -0.097309, -2.3565  , -0.14554 ,  0.28275 ,  2.0053  ,  0.23439 ,\n","       -0.38298 ,  0.69539 , -0.44916 , -0.094157,  0.90527 ,  0.65764 ,\n","        0.27628 ,  0.30688 , -0.57781 , -0.22987 , -0.083043, -0.57236 ,\n","       -0.299   , -0.81112 ,  0.039752, -0.05681 , -0.48879 , -0.18091 ,\n","       -0.28152 , -0.20559 ,  0.4932  , -0.033999, -0.53139 , -0.28297 ,\n","       -1.4475  , -0.18685 ,  0.091177,  0.11454 , -0.28168 , -0.33565 ,\n","       -0.31663 , -0.1089  ,  0.10111 , -0.23737 , -0.64955 , -0.268   ,\n","        0.35096 ,  0.26352 ,  0.59397 ,  0.26741 ], dtype=float32)"]},"execution_count":48,"metadata":{},"output_type":"execute_result"}],"source":["model['go']"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QSgIS-ZYs37-","outputId":"6b4dc024-a080-47aa-9195-6d7adfd1ba52"},"outputs":[{"data":{"text/plain":["100"]},"execution_count":49,"metadata":{},"output_type":"execute_result"}],"source":["len(model['go'])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RzS31lrSs37-","outputId":"bff4f9aa-f1d5-4ce3-9c66-60d637957023"},"outputs":[{"data":{"text/plain":["array([-0.10379 , -0.014792,  0.59933 , -0.51316 , -0.036463,  0.6588  ,\n","       -0.57906 ,  0.17819 ,  0.23663 , -0.21384 ,  0.55339 ,  0.53597 ,\n","        0.041444,  0.16095 ,  0.017093, -0.37242 ,  0.017974,  0.39268 ,\n","       -0.23265 ,  0.1818  ,  0.66405 ,  0.98163 ,  0.42339 ,  0.030581,\n","        0.35015 ,  0.25519 , -0.71182 , -0.42184 ,  0.13068 , -0.47452 ,\n","       -0.08175 ,  0.1574  , -0.13262 ,  0.22679 , -0.16885 , -0.11122 ,\n","       -0.32272 , -0.020978, -0.43345 ,  0.172   , -0.67366 , -0.79052 ,\n","        0.10556 , -0.4219  , -0.12385 , -0.063486, -0.17843 ,  0.56359 ,\n","        0.16986 , -0.17804 ,  0.13956 , -0.20169 ,  0.078985,  1.4497  ,\n","        0.23556 , -2.6014  , -0.5286  , -0.11636 ,  1.7184  ,  0.33254 ,\n","        0.12136 ,  1.1602  , -0.2914  ,  0.47125 ,  0.41869 ,  0.35271 ,\n","        0.47869 , -0.042281, -0.18294 ,  0.1796  , -0.24431 , -0.34042 ,\n","        0.20337 , -0.93676 ,  0.013077,  0.080339, -0.36604 , -0.44005 ,\n","       -0.35393 ,  0.15907 ,  0.55807 ,  0.1492  , -0.86433 ,  0.040305,\n","       -1.0939  , -0.26386 , -0.29494 ,  0.25696 , -0.33718 , -0.086468,\n","       -0.24246 , -0.21114 ,  0.099632,  0.12815 , -0.78714 , -0.51785 ,\n","       -0.10944 ,  0.9763  ,  0.57032 ,  0.13581 ], dtype=float32)"]},"execution_count":50,"metadata":{},"output_type":"execute_result"}],"source":["model['away']"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cuVLN2x0s37-","outputId":"42e55c16-9efe-422a-b133-0dcf72fddde6"},"outputs":[{"data":{"text/plain":["array([-0.091342  ,  0.223404  ,  0.58856   , -0.614765  , -0.0838365 ,\n","        0.5387    , -0.43531   ,  0.349125  ,  0.163308  , -0.28223   ,\n","        0.53547   ,  0.52797496,  0.096812  ,  0.2879    , -0.0533385 ,\n","       -0.37232   ,  0.022637  ,  0.574705  , -0.553275  ,  0.385575  ,\n","        0.565335  ,  0.805405  ,  0.2579965 ,  0.0088565 ,  0.1674905 ,\n","        0.25543   , -0.571035  , -0.59926   ,  0.422585  , -0.42896   ,\n","       -0.389065  ,  0.19631   , -0.00933   ,  0.127285  , -0.0487465 ,\n","        0.381435  , -0.22540998,  0.021299  , -0.1827915 , -0.16490501,\n","       -0.47944498, -0.431528  , -0.20091   , -0.55665   , -0.32982   ,\n","       -0.088548  , -0.28038502,  0.219725  ,  0.090537  , -0.67012   ,\n","        0.0883085 , -0.19332   ,  0.0465725 ,  1.160815  ,  0.0691255 ,\n","       -2.47895   , -0.33707   ,  0.083195  ,  1.86185   ,  0.283465  ,\n","       -0.13081   ,  0.927795  , -0.37028   ,  0.1885465 ,  0.66198   ,\n","        0.505175  ,  0.37748498,  0.1322995 , -0.380375  , -0.025135  ,\n","       -0.1636765 , -0.45639   , -0.047815  , -0.87394   ,  0.0264145 ,\n","        0.0117645 , -0.427415  , -0.31048   , -0.317725  , -0.02326   ,\n","        0.525635  ,  0.05760051, -0.69786   , -0.1213325 , -1.2707    ,\n","       -0.225355  , -0.1018815 ,  0.18575001, -0.30943   , -0.211059  ,\n","       -0.279545  , -0.16002001,  0.100371  , -0.05461   , -0.71834505,\n","       -0.392925  ,  0.12075999,  0.61991   ,  0.582145  ,  0.20161   ],\n","      dtype=float32)"]},"execution_count":51,"metadata":{},"output_type":"execute_result"}],"source":["(model['go'] + model['away'])/2"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hQdNgj78s37_"},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.12"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":0}